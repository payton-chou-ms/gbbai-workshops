{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 4: Data Analyzer\n",
    "**`Data Analyzer`** is an agent focused on data analysis, responsible for extracting valuable information from structured data (such as CSV files exported from databases), supporting two main tasks:\n",
    "\n",
    "1. **Anomaly Detection**: Identifying potential anomalous events in network security (such as abnormal traffic, unauthorized access, or attack behaviors).\n",
    "2. **Trend Prediction**: Predicting future security situations based on historical data (such as attack frequency trends, network traffic changes, and potential threat activity).\n",
    "\n",
    "Working in conjunction with **TimeGPT** (time series analysis tool), **Data Analyzer** can generate intuitive analysis results and return them in visual or data format to assist with network security decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define - analyze_data\n",
    "\n",
    "分析數據集並執行指定的分析方法（預測或異常檢測）\n",
    "此函數根據 file_name 參數讀取預定義的數據集，執行選定的分析方法（forecast 或 anomaly_detection），並以 JSON 格式 返回結果。\n",
    "\n",
    "若選擇 預測（forecast），則根據歷史數據生成未來的預測值，可設定 預測範圍（horizon），並可選擇進行 微調步驟（fine-tuning steps）。\n",
    "\n",
    "若選擇 異常檢測（anomaly_detection），則識別數據中的異常點。\n",
    "\n",
    "函數參數（Parameters）\n",
    "file_name（str）：要分析的數據集名稱。\n",
    "\n",
    "method（str）：選擇的分析方法，必須為 forecast 或 anomaly_detection：\n",
    "\n",
    "forecast：基於歷史數據預測未來值。\n",
    "\n",
    "anomaly_detection：識別數據中的異常模式。\n",
    "\n",
    "horizon（int，選填）：預測範圍，即要預測的未來步數。僅適用於 forecast 方法，預設為 0。\n",
    "\n",
    "ftSteps（int，選填）：執行 微調步驟 的次數。僅適用於 forecast 方法，預設為 0。\n",
    "\n",
    "函數返回（Return）\n",
    "以 JSON 字符串 返回分析結果，具體內容依 method 選擇的分析方法而定：\n",
    "\n",
    "對於 forecast，結果包括 預測值 和 可視化圖表。\n",
    "\n",
    "對於 anomaly_detection，結果包含 檢測出的異常數據點 和 可視化圖表。\n",
    "\n",
    "若發生錯誤，則返回包含 錯誤訊息 的 JSON 結構。\n",
    "\n",
    "返回類型（rtype）：str（JSON 格式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Any, Optional, Literal, Set, Callable\n",
    "from nixtla import NixtlaClient\n",
    "\n",
    "\n",
    "def analyze_data(file_path: str,\n",
    "                 method: Literal['forecast', 'anomaly_detection'],\n",
    "                 horizon: Optional[int] = 0,\n",
    "                 ftSteps: Optional[int] = 0) -> str:\n",
    "    \"\"\"\n",
    "    Analyze a dataset using the specified analysis method (forecasting or anomaly detection).\n",
    "\n",
    "    This function reads a pre-defined dataset based on the provided `file_name` argument, \n",
    "    performs the selected analysis method (`forecast` or `anomaly_detection`), and \n",
    "    returns the results in JSON format. If forecasting is selected, it generates \n",
    "    predictions over a specified horizon and optionally uses fine-tuning steps. \n",
    "    If anomaly detection is selected, it identifies anomalies in the data.\n",
    "\n",
    "    :param file_name: The name of the dataset to analyze. \n",
    "\n",
    "    :param method: The analysis method to use. Must be one of ['forecast', 'anomaly_detection']:\n",
    "                   - 'forecast': Predicts future values based on historical data.\n",
    "                   - 'anomaly_detection': Detects anomalies in the data.\n",
    "\n",
    "    :param horizon: (Optional) The forecast horizon, i.e., the number of future steps to predict.\n",
    "                    Only applicable when `method='forecast'`. Default is 0.\n",
    "\n",
    "    :param ftSteps: (Optional) The number of fine-tuning steps to apply during forecasting.\n",
    "                    Only applicable when `method='forecast'`. Default is 0.\n",
    "\n",
    "    :return: A JSON string containing the results of the analysis. The structure of the output depends on\n",
    "             the selected method:\n",
    "             - For `forecast`, it includes forecasted values and a visualization.\n",
    "             - For `anomaly_detection`, it includes detected anomalies and a visualization.\n",
    "             If an error occurs, the returned JSON contains an error message.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.getenv(\"TIME_GEN_ENDPOINT\") is None or os.getenv(\"TIME_GEN_KEY\") is None:\n",
    "        if method == 'forecast':\n",
    "            return \"./figures/Intrusion_Attempts_forecast_plot.png\"\n",
    "        else:\n",
    "            return \"./figures/Incident_Detection_Rate_anomalies_plot.png\"\n",
    "    \n",
    "    nixtla_client = NixtlaClient(\n",
    "        base_url=os.getenv(\"TIME_GEN_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"TIME_GEN_KEY\"),\n",
    "    )\n",
    "\n",
    "    if file_path is not None:\n",
    "        file_path = file_path if file_path.endswith(\n",
    "            'csv') else f'./data/{file_path}.csv'\n",
    "        file_name = file_path.split('/')[-1].split('.')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        print(df.head())  # 查看前幾行數據\n",
    "        print(df.info())  # 查看數據框的結構\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        print(df.info())  # 查看數據框的結構\n",
    "        \n",
    "        # Initialize variables\n",
    "        horizon_int = None\n",
    "        ftSteps_int = None\n",
    "\n",
    "        try:\n",
    "            horizon_int = int(horizon)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            return f\"Error converting 'horizon': {e}\"\n",
    "\n",
    "        try:\n",
    "            ftSteps_int = int(ftSteps)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            return f\"Error converting 'ftSteps': {e}\"\n",
    "\n",
    "        if ftSteps is None:\n",
    "            ftSteps_int = 0\n",
    "\n",
    "        try:\n",
    "            if method == 'forecast':\n",
    "                try:\n",
    "                    forecast_df = nixtla_client.forecast(\n",
    "                        df=df,\n",
    "                        h=horizon_int,\n",
    "                        finetune_steps=ftSteps_int,\n",
    "                        time_col=\"timestamp\",\n",
    "                        target_col=\"value\",\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during forecast: {e}\")\n",
    "                    return json.dumps({\"error\": str(e)})\n",
    "                fig = nixtla_client.plot(\n",
    "                    df=df, forecasts_df=forecast_df, time_col=\"timestamp\", target_col=\"value\"\n",
    "                )\n",
    "\n",
    "                ax = fig.axes[0]\n",
    "                ax.legend([\"Actual Values\", \"Forecasted Values\"],\n",
    "                          loc=\"upper right\", bbox_to_anchor=(1.14, 1), borderaxespad=0)\n",
    "                ax.set_title(f\"{file_name}: Forecasted vs Actual Values\", fontsize=18,\n",
    "                             fontweight=\"bold\", color=\"teal\", pad=15)\n",
    "\n",
    "                fig_name = f\"./figures/{file_name}_forecast_plot.png\"\n",
    "                fig.savefig(fig_name, dpi=300)\n",
    "\n",
    "                return fig_name\n",
    "            elif method == \"anomaly_detection\":\n",
    "                anomalies_df = nixtla_client.detect_anomalies(\n",
    "                    df,\n",
    "                    time_col=\"timestamp\",\n",
    "                    target_col=\"value\",\n",
    "                    freq=\"D\",\n",
    "                )\n",
    "                anomalies_df = anomalies_df.rename(columns={\n",
    "                    \"TimeGEN\": \"TimeGPT\",\n",
    "                    \"TimeGEN-lo-99\": \"TimeGPT-lo-99\",\n",
    "                    \"TimeGEN-hi-99\": \"TimeGPT-hi-99\"\n",
    "                })\n",
    "\n",
    "                fig = nixtla_client.plot(\n",
    "                    df, anomalies_df, time_col=\"timestamp\", target_col=\"value\")\n",
    "\n",
    "                ax = fig.axes[0]\n",
    "                ax.legend([\"Actual Values\", \"TimeGPT\", \"TimeGPT_level_99\", \"TimeGPT_anomalies_level_99\"],\n",
    "                          loc=\"upper right\", bbox_to_anchor=(1.21, 1), borderaxespad=0)\n",
    "                ax.set_title(f\"{file_name}: Anomalies on Actual Values\", fontsize=18,\n",
    "                             fontweight=\"bold\", color=\"teal\", pad=15)\n",
    "\n",
    "                fig_name = f\"./figures/{file_name}_anomalies_plot.png\"\n",
    "                fig.savefig(fig_name, dpi=300)\n",
    "\n",
    "                return fig_name\n",
    "            else:\n",
    "                return \"Invalid method specified.\"\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "    else:\n",
    "        return \"No data file provided.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp  value\n",
      "0  1949-01-01    112\n",
      "1  1949-02-01    118\n",
      "2  1949-03-01    132\n",
      "3  1949-04-01    129\n",
      "4  1949-05-01    121\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   timestamp  144 non-null    object\n",
      " 1   value      144 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   timestamp  144 non-null    datetime64[ns]\n",
      " 1   value      144 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(1)\n",
      "memory usage: 2.4 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Attempt 1 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 2 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 3 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 4 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 5 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 6 failed...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during forecast: 1 validation error for ParsingModel[HttpValidationError]\n",
      "__root__ -> detail\n",
      "  value is not a valid list (type=type_error.list)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"error\": \"1 validation error for ParsingModel[HttpValidationError]\\\\n__root__ -> detail\\\\n  value is not a valid list (type=type_error.list)\"}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_data(\"./data/intrusion_attempts.csv\", 'forecast', horizon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Calling Anomaly Detector Endpoint...\n",
      "INFO:nixtla.nixtla_client:Attempt 1 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 2 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 3 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 4 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 5 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 6 failed...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"error\": \"1 validation error for ParsingModel[HttpValidationError]\\\\n__root__ -> detail\\\\n  value is not a valid list (type=type_error.list)\"}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_data(\"./data/incident_detection_rate.csv\", 'anomaly_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.environment:No environment configuration found.\n",
      "INFO:azure.identity._credentials.managed_identity:ManagedIdentityCredential will use IMDS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import FunctionTool\n",
    "\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "\n",
    "logging.getLogger('azure.core.pipeline.policies.http_logging_policy').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'analyze_data', 'description': 'Analyze a dataset using the specified analysis method (forecasting or anomaly detection).', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'No description'}, 'method': {'type': 'string', 'description': \"The analysis method to use. Must be one of ['forecast', 'anomaly_detection']:\"}, 'horizon': {'type': ['integer', 'null'], 'description': '(Optional) The forecast horizon, i.e., the number of future steps to predict.'}, 'ftSteps': {'type': ['integer', 'null'], 'description': '(Optional) The number of fine-tuning steps to apply during forecasting.'}}, 'required': ['file_path', 'method']}}}]\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Set, Callable\n",
    "from azure.ai.projects.models import FunctionTool\n",
    "\n",
    "\n",
    "user_functions: Set[Callable[..., Any]] = {analyze_data}\n",
    "functions = FunctionTool(functions=user_functions)\n",
    "print(functions.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.chained:DefaultAzureCredential acquired a token from AzureCliCredential\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_TZ8XzqpP0rld787V80Nv3Yhb\n"
     ]
    }
   ],
   "source": [
    "data_analyzer = project_client.agents.create_agent(\n",
    "    model=os.environ[\"CHAT_MODEL\"],\n",
    "    name=\"data_analyzer\",\n",
    "    description=\"An agent that analyzes data using forecasting or anomaly detection.\",\n",
    "    instructions=\"Hello, you are helpful assistant.\",\n",
    "    tools=functions.definitions,\n",
    "    # Parameters\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    # Metadata\n",
    "    metadata={\"group\": \"internet_threat_analysis\"},\n",
    ")\n",
    "\n",
    "print(f\"Created agent, agent ID: {data_analyzer.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_a9Nl41ZKfML2YBN5cNODwAGw\n",
      "Created run, ID: run_GFqEnGcdm2AJ1FVqb71DU2Vh\n",
      "Current run status: RunStatus.IN_PROGRESS\n",
      "Executing tool call: {'id': 'call_MCHNAmS2q7v1RGKjgsLhiY5v', 'type': 'function', 'function': {'name': 'analyze_data', 'arguments': '{\"file_path\": \"./data/intrusion_attempts.csv\", \"method\": \"forecast\", \"horizon\": 10}'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n",
      "INFO:nixtla.nixtla_client:Attempt 1 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 2 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 3 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 4 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 5 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 6 failed...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool call: {'id': 'call_0egTsM1WmbGIC1eFl771hK5G', 'type': 'function', 'function': {'name': 'analyze_data', 'arguments': '{\"file_path\": \"./data/incident_detection_rate.csv\", \"method\": \"anomaly_detection\"}'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Calling Anomaly Detector Endpoint...\n",
      "INFO:nixtla.nixtla_client:Attempt 1 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 2 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 3 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 4 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 5 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 6 failed...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool outputs: [{'tool_call_id': 'call_MCHNAmS2q7v1RGKjgsLhiY5v', 'output': '{\"error\": \"1 validation error for ParsingModel[HttpValidationError]\\\\n__root__ -> detail\\\\n  value is not a valid list (type=type_error.list)\"}'}, {'tool_call_id': 'call_0egTsM1WmbGIC1eFl771hK5G', 'output': '{\"error\": \"1 validation error for ParsingModel[HttpValidationError]\\\\n__root__ -> detail\\\\n  value is not a valid list (type=type_error.list)\"}'}]\n",
      "Current run status: RunStatus.REQUIRES_ACTION\n",
      "Current run status: RunStatus.IN_PROGRESS\n",
      "Current run status: RunStatus.IN_PROGRESS\n",
      "Current run status: RunStatus.IN_PROGRESS\n",
      "Executing tool call: {'id': 'call_Fj70nzlQCegDrAT4M6Rq78p9', 'type': 'function', 'function': {'name': 'analyze_data', 'arguments': '{\"file_path\": \"./data/intrusion_attempts.csv\", \"method\": \"forecast\", \"horizon\": 10}'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n",
      "INFO:nixtla.nixtla_client:Attempt 1 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 2 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 3 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 4 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 5 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 6 failed...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool call: {'id': 'call_tVDc6AFQTmYEs61cWAdXjeGH', 'type': 'function', 'function': {'name': 'analyze_data', 'arguments': '{\"file_path\": \"./data/incident_detection_rate.csv\", \"method\": \"anomaly_detection\"}'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Calling Anomaly Detector Endpoint...\n",
      "INFO:nixtla.nixtla_client:Attempt 1 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 2 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 3 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 4 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 5 failed...\n",
      "INFO:nixtla.nixtla_client:Attempt 6 failed...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool outputs: [{'tool_call_id': 'call_Fj70nzlQCegDrAT4M6Rq78p9', 'output': '{\"error\": \"1 validation error for ParsingModel[HttpValidationError]\\\\n__root__ -> detail\\\\n  value is not a valid list (type=type_error.list)\"}'}, {'tool_call_id': 'call_tVDc6AFQTmYEs61cWAdXjeGH', 'output': '{\"error\": \"1 validation error for ParsingModel[HttpValidationError]\\\\n__root__ -> detail\\\\n  value is not a valid list (type=type_error.list)\"}'}]\n",
      "Current run status: RunStatus.REQUIRES_ACTION\n",
      "Current run status: RunStatus.COMPLETED\n",
      "Run completed with status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from azure.ai.projects.models import RequiredFunctionToolCall, SubmitToolOutputsAction, ToolOutput\n",
    "\n",
    "\n",
    "agent_id = data_analyzer.id\n",
    "\n",
    "\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message_1 = project_client.agents.create_message(\n",
    "    thread_id=thread.id, role=\"assistant\", content=\"\"\"The intrusion attempts data has been successfully fetched and saved as a CSV file. You can find it at the following path: ./data/intrusion_attempts.csv.\n",
    "    \n",
    "    The incident detection data has been successfully fetched and saved as a CSV file. You can find it at the following path: ./data/incident_detection_rate.csv\n",
    "    \"\"\"\n",
    ")\n",
    "message_2 = project_client.agents.create_message(\n",
    "    thread_id=thread.id, role=\"user\", content=\"Hello, create a 10-day forecast using the intrusion attempts data. And detect anomalies in the incident detection data.\"\n",
    ")\n",
    "\n",
    "# Create and process assistant run in thread with tools\n",
    "run = project_client.agents.create_run(thread_id=thread.id, assistant_id=agent_id)\n",
    "print(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    time.sleep(1)\n",
    "    run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        if not tool_calls:\n",
    "            print(\"No tool calls provided - cancelling run\")\n",
    "            project_client.agents.cancel_run(\n",
    "                thread_id=thread.id, run_id=run.id)\n",
    "            break\n",
    "\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                try:\n",
    "                    print(f\"Executing tool call: {tool_call}\")\n",
    "                    output = functions.execute(tool_call)\n",
    "                    tool_outputs.append(\n",
    "                        ToolOutput(\n",
    "                            tool_call_id=tool_call.id,\n",
    "                            output=output,\n",
    "                        )\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error executing tool_call {tool_call.id}: {e}\")\n",
    "\n",
    "        print(f\"Tool outputs: {tool_outputs}\")\n",
    "        if tool_outputs:\n",
    "            project_client.agents.submit_tool_outputs_to_run(\n",
    "                thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs\n",
    "            )\n",
    "\n",
    "    print(f\"Current run status: {run.status}\")\n",
    "\n",
    "print(f\"Run completed with status: {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._internal.decorators:AzureCliCredential.get_token_info succeeded\n",
      "INFO:azure.identity._credentials.default:DefaultAzureCredential acquired a token from AzureCliCredential\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Conversation\n",
       "___\n",
       "### **Assistant** (2025-03-27 19:13:07 台北標準時間)\n",
       "The intrusion attempts data has been successfully fetched and saved as a CSV file. You can find it at the following path: ./data/intrusion_attempts.csv.\n",
       "\n",
       "    The incident detection data has been successfully fetched and saved as a CSV file. You can find it at the following path: ./data/incident_detection_rate.csv\n",
       "    \n",
       "___\n",
       "### **User** (2025-03-27 19:13:08 台北標準時間)\n",
       "Hello, create a 10-day forecast using the intrusion attempts data. And detect anomalies in the incident detection data.\n",
       "___\n",
       "### **Assistant** (2025-03-27 19:15:13 台北標準時間)\n",
       "It seems there was an error while attempting to process the data for forecasting and anomaly detection. Let me try again to perform the analyses.\n",
       "___\n",
       "### **Assistant** (2025-03-27 19:17:13 台北標準時間)\n",
       "It appears that there is a persistent issue with processing the data files for both the forecasting and anomaly detection. The errors indicate that the input values are not valid lists, suggesting a potential issue with the data format or content in the CSV files.\n",
       "\n",
       "To resolve this, I can check the contents of the CSV files to ensure they are properly formatted. Would you like me to do that?\n",
       "___"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import helper\n",
    "\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "display(Markdown(helper.get_conversation_md(messages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
