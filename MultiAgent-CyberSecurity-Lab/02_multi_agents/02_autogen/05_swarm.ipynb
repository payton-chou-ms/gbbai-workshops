{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swarm\n",
    "`Swarm` implements a team in which agents can hand off task to other agents based on their capabilities. It is a multi-agent design pattern first introduced by OpenAI in an experimental project. The key idea is to let agent delegate tasks to other agents using a special tool call, while all agents share the same message context. This enables agents to make local decisions about task planning, rather than relying on a central orchestrator such as in `SelectorGroupChat`.\n",
    "\n",
    "> `Swarm` is a high-level API. If you need more, control and customization that is not supported by this API, you can take a look,\n",
    "at the [Handoff Pattern](../../core-user-guide/design-patterns/handoffs.ipynb), in the Core API documentation and implement your own version of the Swarm pattern.,\n",
    "\n",
    "\n",
    "### How Does It Work?\n",
    "At its core, the `Swarm` team is a group chat where agents take turn to generate a response. Similar to `SelectorGroupChat` and `RoundRobinGroupChat`, participant agents broadcast their responses so all agents share the same message context.\n",
    "\n",
    "Different from the other two group chat teams, at each turn, the speaker agent is selected based on the most recent `HandoffMessage` message in the context. This naturally requires each agent in the team to be able to generate `HandoffMessage` to signal which other agents that it hands off to.\n",
    "\n",
    "For `AssistantAgent`, you can set the handoffs argument to specify which agents it can hand off to. You can use `Handoff` to customize the message content and handoff behavior.\n",
    "\n",
    "The overall process can be summarized as follows:\n",
    "\n",
    "- Each agent has the ability to generate `HandoffMessage` to signal which other agents it can hand off to. For `AssistantAgent`, this means setting the handoffs argument.\n",
    "\n",
    "- When the team starts on a task, the first speaker agents operate on the task and make localized decision about whether to hand off and to whom.\n",
    "\n",
    "- When an agent generates a `HandoffMessage`, the receiving agent takes over the task with the same message context.\n",
    "\n",
    "- The process continues until a termination condition is met.\n",
    "\n",
    "In this section, we will show you two examples of how to use the `Swarm` team:\n",
    "\n",
    "1. A customer support team with human-in-the-loop handoff.\n",
    "\n",
    "2. An autonomous team for content generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Support Example\n",
    "\n",
    "<Image src='docs/swarm_customer_support.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This system implements a flights refund scenario with two agents:\n",
    "\n",
    "- Travel Agent: Handles general travel and refund coordination.\n",
    "\n",
    "- Flights Refunder: Specializes in processing flight refunds with the `refund_flight` tool.\n",
    "\n",
    "Additionally, we let the user interact with the agents, when agents handoff to \"user\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "1. The Travel Agent initiates the conversation and evaluates the user’s request.\n",
    "\n",
    "2. Based on the request:\n",
    "\n",
    "    - For refund-related tasks, the Travel Agent hands off to the Flights Refunder.\n",
    "\n",
    "    - For information needed from the customer, either agent can hand off to the \"user\".\n",
    "\n",
    "3. The Flights Refunder processes refunds using the `refund_flight` tool when appropriate.\n",
    "\n",
    "4. If an agent hands off to the \"user\", the team execution will stop and wait for the user to input a response.\n",
    "\n",
    "5. When the user provides input, it’s sent back to the team as a `HandoffMessage`. This message is directed to the agent that originally requested user input.\n",
    "\n",
    "6. The process continues until the Travel Agent determines the task is complete and terminates the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "# load_dotenv(\"../../../../.env\")\n",
    "# os.environ.get(\"AZURE_OPENAI_ENDPOINT_GPT_4o\")\n",
    "\n",
    "# api_key = os.environ[\"AZURE_OPENAI_API_KEY_GPT_4o\"]\n",
    "# api_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT_GPT_4o\"]\n",
    "# deployment_name = os.environ[\"AZURE_OPENAI_MODEl_GPT_4o\"]\n",
    "\n",
    "# aoai_client = AzureOpenAIChatCompletionClient(\n",
    "#     azure_endpoint=api_endpoint,\n",
    "#     model=\"gpt-4o\",\n",
    "#     azure_deployment=deployment_name,\n",
    "#     api_key=api_key,\n",
    "#     api_version=\"2024-06-01\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv('CHAT_MODEL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "\n",
    "base_url = project_client.inference.get_azure_openai_client(\n",
    "    api_version=\"2024-06-01\").base_url\n",
    "\n",
    "api_endpoint = f'https://{base_url.host}/'\n",
    "\n",
    "api_key = project_client.inference.get_azure_openai_client(\n",
    "    api_version=\"2024-06-01\").api_key\n",
    "\n",
    "deployment_name = os.environ[\"CHAT_MODEL\"]\n",
    "\n",
    "aoai_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=api_endpoint,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    azure_deployment=deployment_name,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-06-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from autogen_agentchat.teams import Swarm\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import HandoffMessage\n",
    "from autogen_agentchat.conditions import HandoffTermination, TextMentionTermination\n",
    "\n",
    "\n",
    "def refund_flight(flight_id: str) -> str:\n",
    "    \"\"\"Refund a flight\"\"\"\n",
    "    return f\"Flight {flight_id} refunded\"\n",
    "\n",
    "\n",
    "travel_agent = AssistantAgent(\n",
    "    \"travel_agent\",\n",
    "    model_client=aoai_client,\n",
    "    handoffs=[\"flights_refunder\", \"user\"],\n",
    "    system_message=\"\"\"You are a travel agent.\n",
    "    The flights_refunder is in charge of refunding flights.\n",
    "    If you need information from the user, you must first send your message, then you can handoff to the user.\n",
    "    Reply TERMINATE when the travel planning is complete.\"\"\",\n",
    ")\n",
    "\n",
    "flights_refunder = AssistantAgent(\n",
    "    \"flights_refunder\",\n",
    "    model_client=aoai_client,\n",
    "    handoffs=[\"travel_agent\", \"user\"],\n",
    "    tools=[refund_flight],\n",
    "    system_message=\"\"\"You are an agent specialized in refunding flights.\n",
    "    You only need flight reference numbers to refund a flight.\n",
    "    You have the ability to refund a flight using the refund_flight tool.\n",
    "    If you need information from the user, you must first send your message, then you can handoff to the user.\n",
    "    When the transaction is complete, handoff to the travel agent to finalize.\"\"\",\n",
    ")\n",
    "\n",
    "termination = HandoffTermination(\n",
    "    target=\"user\") | TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "team = Swarm([travel_agent, flights_refunder],\n",
    "             termination_condition=termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# await team.reset()  # Reset the team for the next run.\n",
    "\n",
    "task = \"I need to refund my flight.\"\n",
    "\n",
    "\n",
    "async def run_team_stream() -> None:\n",
    "    task_result = await Console(team.run_stream(task=task))\n",
    "    last_message = task_result.messages[-1]\n",
    "\n",
    "    while isinstance(last_message, HandoffMessage) and last_message.target == \"user\":\n",
    "        user_message = input(\"User: \")\n",
    "\n",
    "        task_result = await Console(\n",
    "            team.run_stream(task=HandoffMessage(\n",
    "                source=\"user\", target=last_message.source, content=user_message))\n",
    "        )\n",
    "        last_message = task_result.messages[-1]\n",
    "\n",
    "\n",
    "await run_team_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Research Example\n",
    "\n",
    "<Image src='docs/swarm_stock_research.svg'>\n",
    "\n",
    "This system is designed to perform stock research tasks by leveraging four agents:\n",
    "\n",
    "- **Planner**: The central coordinator that delegates specific tasks to specialized agents based on their expertise. The planner ensures that each agent is utilized efficiently and oversees the overall workflow.\n",
    "\n",
    "- **Financial Analyst**: A specialized agent responsible for analyzing financial metrics and stock data using tools such as get_stock_data.\n",
    "\n",
    "- **News Analyst**: An agent focused on gathering and summarizing recent news articles relevant to the stock, using tools such as get_news.\n",
    "\n",
    "- **Writer**: An agent tasked with compiling the findings from the stock and news analysis into a cohesive final report.\n",
    "\n",
    "## Workflow\n",
    "1. The Planner initiates the research process by delegating tasks to the appropriate agents in a step-by-step manner.\n",
    "\n",
    "2. Each agent performs its task independently and appends their work to the shared message thread/history. Rather than directly returning results to the planner, all agents contribute to and read from this shared message history. When agents generate their work using the LLM, they have access to this shared message history, which provides context and helps track the overall progress of the task.\n",
    "\n",
    "3. Once an agent completes its task, it hands off control back to the planner.\n",
    "\n",
    "4. The process continues until the planner determines that all necessary tasks have been completed and decides to terminate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_stock_data(symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get stock market data for a given symbol\"\"\"\n",
    "    return {\"price\": 180.25, \"volume\": 1000000, \"pe_ratio\": 65.4, \"market_cap\": \"700B\"}\n",
    "\n",
    "\n",
    "async def get_news(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Get recent news articles about a company\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"title\": \"Tesla Expands Cybertruck Production\",\n",
    "            \"date\": \"2024-03-20\",\n",
    "            \"summary\": \"Tesla ramps up Cybertruck manufacturing capacity at Gigafactory Texas, aiming to meet strong demand.\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Tesla FSD Beta Shows Promise\",\n",
    "            \"date\": \"2024-03-19\",\n",
    "            \"summary\": \"Latest Full Self-Driving beta demonstrates significant improvements in urban navigation and safety features.\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Model Y Dominates Global EV Sales\",\n",
    "            \"date\": \"2024-03-18\",\n",
    "            \"summary\": \"Tesla's Model Y becomes best-selling electric vehicle worldwide, capturing significant market share.\",\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = AssistantAgent(\n",
    "    \"planner\",\n",
    "    model_client=aoai_client,\n",
    "    handoffs=[\"financial_analyst\", \"news_analyst\", \"writer\"],\n",
    "    system_message=\"\"\"You are a research planning coordinator.\n",
    "    Coordinate market research by delegating to specialized agents:\n",
    "    - Financial Analyst: For stock data analysis\n",
    "    - News Analyst: For news gathering and analysis\n",
    "    - Writer: For compiling final report\n",
    "    Always send your plan first, then handoff to appropriate agent.\n",
    "    Handoff to a single agent at a time.\n",
    "    Reply TERMINATE when research is complete.\"\"\",\n",
    ")\n",
    "\n",
    "financial_analyst = AssistantAgent(\n",
    "    \"financial_analyst\",\n",
    "    model_client=aoai_client,\n",
    "    handoffs=[\"planner\"],\n",
    "    tools=[get_stock_data],\n",
    "    system_message=\"\"\"You are a financial analyst.\n",
    "    Analyze stock market data using the get_stock_data tool.\n",
    "    Provide insights on financial metrics.\n",
    "    Always handoff back to planner when analysis is complete.\"\"\",\n",
    ")\n",
    "\n",
    "news_analyst = AssistantAgent(\n",
    "    \"news_analyst\",\n",
    "    model_client=aoai_client,\n",
    "    handoffs=[\"planner\"],\n",
    "    tools=[get_news],\n",
    "    system_message=\"\"\"You are a news analyst.\n",
    "    Gather and analyze relevant news using the get_news tool.\n",
    "    Summarize key market insights from news.\n",
    "    Always handoff back to planner when analysis is complete.\"\"\",\n",
    ")\n",
    "\n",
    "writer = AssistantAgent(\n",
    "    \"writer\",\n",
    "    model_client=aoai_client,\n",
    "    handoffs=[\"planner\"],\n",
    "    system_message=\"\"\"You are a financial report writer.\n",
    "    Compile research findings into clear, concise reports.\n",
    "    Always handoff back to planner when writing is complete.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "# Define termination condition\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination = text_termination\n",
    "\n",
    "research_team = Swarm(\n",
    "    participants=[planner, financial_analyst, news_analyst,\n",
    "                  writer], termination_condition=termination\n",
    ")\n",
    "\n",
    "task = \"Conduct market research for TSLA stock\"\n",
    "await Console(research_team.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Show me the market research report here.\"\n",
    "await Console(research_team.run_stream(task=task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
